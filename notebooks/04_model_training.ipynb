{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad66087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null counts:\n",
      " Transaction_ID                  0\n",
      "User_ID                         0\n",
      "Transaction_Amount              0\n",
      "Transaction_Type                0\n",
      "Timestamp                       0\n",
      "Account_Balance                 0\n",
      "Device_Type                     0\n",
      "Location                        0\n",
      "Merchant_Category               0\n",
      "IP_Address_Flag                 0\n",
      "Previous_Fraudulent_Activity    0\n",
      "Daily_Transaction_Count         0\n",
      "Avg_Transaction_Amount_7d       0\n",
      "Failed_Transaction_Count_7d     0\n",
      "Card_Type                       0\n",
      "Card_Age                        0\n",
      "Transaction_Distance            0\n",
      "Authentication_Method           0\n",
      "Risk_Score                      0\n",
      "Is_Weekend                      0\n",
      "Fraud_Label                     0\n",
      "dtype: int64\n",
      "Duplicate rows: 0\n",
      "                Model  Accuracy  Precision    Recall        F1\n",
      "0  LogisticRegression    0.8104   0.733543  0.648607  0.688465\n",
      "1        DecisionTree    1.0000   1.000000  1.000000  1.000000\n",
      "2        RandomForest    1.0000   1.000000  1.000000  1.000000\n",
      "3                 KNN    0.7919   0.766095  0.512074  0.613843\n"
     ]
    }
   ],
   "source": [
    "# This script reads the data, checks it, cleans it, builds features,\n",
    "# trains four models, and prints how well each one works.\n",
    "\n",
    "# 0. Project path setup \n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Tell Python where to find our lib/ modules\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# 1. Standard imports\n",
    "import yaml                  # to read config files\n",
    "import pandas as pd          # for tables of data\n",
    "\n",
    "# 2. Pipeline modules\n",
    "from lib.validate_input import validate_schema, validate_types, check_nulls_and_duplicates\n",
    "   # functions to check columns, data types, missing values, duplicates\n",
    "from lib.clean_data import clean_data\n",
    "   # function to fill missing values and convert timestamps\n",
    "from lib.feature_engineering import engineer_features\n",
    "   # function to create new numeric features and encode categoricals\n",
    "\n",
    "# 3. ML imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "   # split data into train and test sets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "   # simple linear classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "   # tree-based classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "   # ensemble of trees\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "   # nearest-neighbor classifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "   # metrics to measure model performance\n",
    "\n",
    "# 4. Load config + raw data\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)  \n",
    "# get the CSV file path from the config\n",
    "df_raw = pd.read_csv(config['input_data']['file1'])  \n",
    "# read the raw transaction data\n",
    "\n",
    "# 5. Validate schema\n",
    "validate_schema(df_raw)  \n",
    "# ensure required columns like 'Timestamp', 'Fraud_Label', etc. are present\n",
    "\n",
    "# 6. Clean data (converts Timestamp to datetime, fills nulls)\n",
    "df_cleaned = clean_data(df_raw)  \n",
    "# fill numeric nulls with means, categorical nulls with modes,\n",
    "# convert 'Timestamp' to datetime and forward-fill missing dates\n",
    "\n",
    "# 7. Validate types after cleaning\n",
    "type_issues = validate_types(df_cleaned)  \n",
    "# confirm 'Timestamp' column is now a datetime\n",
    "if type_issues:\n",
    "    print(\"Type issues after cleaning:\", type_issues)\n",
    "\n",
    "# 8. Check nulls & duplicates\n",
    "nulls, dupes = check_nulls_and_duplicates(df_cleaned)\n",
    "print(\"Null counts:\\n\", nulls)        # show any remaining missing values\n",
    "print(\"Duplicate rows:\", dupes)       # show count of exact duplicate records\n",
    "\n",
    "# 9. Feature engineering\n",
    "df_model_ready = engineer_features(df_cleaned)\n",
    "# create new numeric columns, scale numbers, encode categories,\n",
    "# and drop any raw ID or timestamp columns inside that function\n",
    "\n",
    "# 10. Define X, y\n",
    "target = 'Fraud_Label' if 'Fraud_Label' in df_model_ready.columns else 'is_fraud'\n",
    "X = df_model_ready.drop(target, axis=1)  \n",
    "y = df_model_ready[target]  \n",
    "# features go in X, the label to predict goes in y\n",
    "\n",
    "if 'Timestamp' in X.columns:\n",
    "    X = X.drop('Timestamp', axis=1)  \n",
    "    # drop any leftover raw datetime column before modeling\n",
    "\n",
    "# 11. Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")  \n",
    "# hold out 20% of data for testing performance on unseen records\n",
    "\n",
    "# 12. Define models (increase max_iter)\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'DecisionTree':       DecisionTreeClassifier(),\n",
    "    'RandomForest':       RandomForestClassifier(),\n",
    "    'KNN':                KNeighborsClassifier()\n",
    "}\n",
    "# list of algorithms we'll train and compare\n",
    "\n",
    "# 13. Train & evaluate\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)         # learn patterns from training data\n",
    "    preds = model.predict(X_test)       # predict on the test set\n",
    "    results.append({\n",
    "        'Model':     name,\n",
    "        'Accuracy':  accuracy_score(y_test, preds),\n",
    "        'Precision': precision_score(y_test, preds),\n",
    "        'Recall':    recall_score(y_test, preds),\n",
    "        'F1':        f1_score(y_test, preds)\n",
    "    })\n",
    "# store accuracy, precision, recall, and F1 for each model\n",
    "\n",
    "# 14. Display results\n",
    "print(pd.DataFrame(results))  \n",
    "# print a table showing how well each classifier performed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1aa3f4",
   "metadata": {},
   "source": [
    "# Results Summary\n",
    "\n",
    "## Nulls and Duplicates\n",
    "\n",
    "All columns report zero missing values and there are no duplicate rows.\n",
    "\n",
    "- The cleaning step filled all nulls and removed duplicates successfully.\n",
    "\n",
    "---\n",
    "\n",
    "## Model Performance\n",
    "\n",
    "| Model              | Accuracy | Precision | Recall  | F1      |\n",
    "|--------------------|---------:|----------:|--------:|--------:|\n",
    "| LogisticRegression |   0.8104 |   0.7335  | 0.6486  | 0.6885 |\n",
    "| DecisionTree       |   1.0000 |   1.0000  | 1.0000  | 1.0000 |\n",
    "| RandomForest       |   1.0000 |   1.0000  | 1.0000  | 1.0000 |\n",
    "| KNN                |   0.7919 |   0.7661  | 0.5121  | 0.6138 |\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "- LogisticRegression  \n",
    "  - Accurately labels about 81% of transactions.  \n",
    "  - Precision 0.73 means 73% of flagged frauds are real.  \n",
    "  - Recall 0.65 means it catches 65% of actual frauds.\n",
    "\n",
    "- DecisionTree and RandomForest  \n",
    "  - Perfect scores (100%) indicate overfitting on the training data.  \n",
    "  - They may fail to generalize to new, unseen data.\n",
    "\n",
    "- KNN  \n",
    "  - Accuracy near 79% and high precision (0.77).  \n",
    "  - Recall 0.51 means it misses almost half of real frauds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4999e0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Acc=0.8104, Prec=0.7335, Rec=0.6486, F1=0.6885\n",
      "DecisionTree: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "RandomForest: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "KNN: Acc=0.7919, Prec=0.7661, Rec=0.5121, F1=0.6138\n",
      "Bagging_Tree: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "AdaBoost: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n",
      "GradientBoosting: Acc=1.0000, Prec=1.0000, Rec=1.0000, F1=1.0000\n"
     ]
    }
   ],
   "source": [
    "# Day 3 Theory: Ensemble Methods and Robust Evaluation\n",
    "# On Day 3 we expand from single classifiers to ensembles:\n",
    "# - Bagging cuts variance by averaging many trees built on bootstrap samples.\n",
    "# - Boosting cuts bias by sequentially focusing new learners on previous errors.\n",
    "# We then measure four key metrics on our held-out set:\n",
    "#  • Accuracy: overall fraction of correct predictions  \n",
    "#  • Precision: fraction of predicted frauds that were real (false alarm rate)  \n",
    "#  • Recall: fraction of actual frauds we correctly flagged (missed fraud rate)  \n",
    "#  • F1 Score: harmonic mean of precision & recall for balanced evaluation  \n",
    "\n",
    "# minimal imports needed here for Day 3 ensembles and full metric set\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Extend our models dict with three ensemble variants\n",
    "# hyperparams: Bagging uses shallow trees (max_depth=5) with 50 estimators to cut variance;\n",
    "# AdaBoost runs 50 rounds at lr=1.0 to spotlight hard cases; GradientBoosting uses 100 estimators at lr=0.1 for fine-grained bias reduction\n",
    "models.update({\n",
    "    'Bagging_Tree': BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=5),\n",
    "        n_estimators=50,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'AdaBoost': AdaBoostClassifier(\n",
    "        n_estimators=50,\n",
    "        learning_rate=1.0,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "})\n",
    "\n",
    "# Day 3: train each model and compute all four metrics\n",
    "# 1) Fit on X_train, y_train  \n",
    "# 2) Predict on X_test  \n",
    "# 3) Calculate accuracy, precision, recall, and F1 to compare how well each model balances catching fraud vs. false alarms\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec  = recall_score(y_test, y_pred)\n",
    "    f1   = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{name}: Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e6c4e",
   "metadata": {},
   "source": [
    "# Results: Ensemble Models Evaluation\n",
    "\n",
    "| Model               | Accuracy | Precision | Recall  | F1 Score |\n",
    "|---------------------|----------|-----------|---------|----------|\n",
    "| LogisticRegression  | 0.8104   | 0.7335    | 0.6486  | 0.6885   |\n",
    "| DecisionTree        | 1.0000   | 1.0000    | 1.0000  | 1.0000   |\n",
    "| RandomForest        | 1.0000   | 1.0000    | 1.0000  | 1.0000   |\n",
    "| KNN                 | 0.7919   | 0.7661    | 0.5121  | 0.6138   |\n",
    "| Bagging_Tree        | 1.0000   | 1.0000    | 1.0000  | 1.0000   |\n",
    "| AdaBoost            | 1.0000   | 1.0000    | 1.0000  | 1.0000   |\n",
    "| GradientBoosting    | 1.0000   | 1.0000    | 1.0000  | 1.0000   |\n",
    "\n",
    "## Interpretation Aligned with Day 3 Theory\n",
    "\n",
    "- **LogisticRegression**  \n",
    "  Provides a balanced baseline: 81% accuracy, decent precision (0.73), moderate recall (0.65), resulting in an F1 of 0.69. It’s predictable and less prone to overfitting.\n",
    "\n",
    "- **DecisionTree & RandomForest**  \n",
    "  Both achieve perfect scores, which signals overfitting to the test split. In real-world fraud scenarios, this perfect classification is suspicious and likely won’t hold on new data.\n",
    "\n",
    "- **KNN**  \n",
    "  Delivers lower recall (0.51) than logistic but higher precision (0.77), indicating it’s conservative (fewer false positives, more false negatives). Its overall F1 (0.61) trails logistic regression.\n",
    "\n",
    "- **Bagging_Tree, AdaBoost, GradientBoosting**  \n",
    "  All ensembles report 100% across metrics here. As with single trees, they’ve overfit the test set. They will need parameter tuning or validation strategies to ensure reliable generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa4132b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../my_streamlit_app/models/feature_names.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Make sure models/ folder exists inside your Streamlit app folder\n",
    "Path(\"../my_streamlit_app/models\").mkdir(exist_ok=True)\n",
    "\n",
    "# Save each fitted model\n",
    "for name, mdl in models.items():\n",
    "    joblib.dump(mdl, f\"../my_streamlit_app/models/{name}.pkl\")\n",
    "\n",
    "# Save feature names to the same folder\n",
    "feature_names = X_train.columns.tolist()\n",
    "joblib.dump(feature_names, \"../my_streamlit_app/models/feature_names.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
