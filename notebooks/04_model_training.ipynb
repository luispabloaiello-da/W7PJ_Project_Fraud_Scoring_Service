{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad66087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null counts:\n",
      " Transaction_ID                  0\n",
      "User_ID                         0\n",
      "Transaction_Amount              0\n",
      "Transaction_Type                0\n",
      "Timestamp                       0\n",
      "Account_Balance                 0\n",
      "Device_Type                     0\n",
      "Location                        0\n",
      "Merchant_Category               0\n",
      "IP_Address_Flag                 0\n",
      "Previous_Fraudulent_Activity    0\n",
      "Daily_Transaction_Count         0\n",
      "Avg_Transaction_Amount_7d       0\n",
      "Failed_Transaction_Count_7d     0\n",
      "Card_Type                       0\n",
      "Card_Age                        0\n",
      "Transaction_Distance            0\n",
      "Authentication_Method           0\n",
      "Risk_Score                      0\n",
      "Is_Weekend                      0\n",
      "Fraud_Label                     0\n",
      "dtype: int64\n",
      "Duplicate rows: 0\n",
      "                Model  Accuracy  Precision    Recall        F1\n",
      "0  LogisticRegression    0.8104   0.733543  0.648607  0.688465\n",
      "1        DecisionTree    1.0000   1.000000  1.000000  1.000000\n",
      "2        RandomForest    1.0000   1.000000  1.000000  1.000000\n",
      "3                 KNN    0.7919   0.766095  0.512074  0.613843\n"
     ]
    }
   ],
   "source": [
    "# This script reads the data, checks it, cleans it, builds features,\n",
    "# trains four models, and prints how well each one works.\n",
    "\n",
    "# 0. Project path setup \n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Tell Python where to find our lib/ modules\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# 1. Standard imports\n",
    "import yaml                  # to read config files\n",
    "import pandas as pd          # for tables of data\n",
    "\n",
    "# 2. Pipeline modules\n",
    "from lib.validate_input import validate_schema, validate_types, check_nulls_and_duplicates\n",
    "   # functions to check columns, data types, missing values, duplicates\n",
    "from lib.clean_data import clean_data\n",
    "   # function to fill missing values and convert timestamps\n",
    "from lib.feature_engineering import engineer_features\n",
    "   # function to create new numeric features and encode categoricals\n",
    "\n",
    "# 3. ML imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "   # split data into train and test sets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "   # simple linear classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "   # tree-based classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "   # ensemble of trees\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "   # nearest-neighbor classifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "   # metrics to measure model performance\n",
    "\n",
    "# 4. Load config + raw data\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)  \n",
    "# get the CSV file path from the config\n",
    "df_raw = pd.read_csv(config['input_data']['file1'])  \n",
    "# read the raw transaction data\n",
    "\n",
    "# 5. Validate schema\n",
    "validate_schema(df_raw)  \n",
    "# ensure required columns like 'Timestamp', 'Fraud_Label', etc. are present\n",
    "\n",
    "# 6. Clean data (converts Timestamp to datetime, fills nulls)\n",
    "df_cleaned = clean_data(df_raw)  \n",
    "# fill numeric nulls with means, categorical nulls with modes,\n",
    "# convert 'Timestamp' to datetime and forward-fill missing dates\n",
    "\n",
    "# 7. Validate types after cleaning\n",
    "type_issues = validate_types(df_cleaned)  \n",
    "# confirm 'Timestamp' column is now a datetime\n",
    "if type_issues:\n",
    "    print(\"Type issues after cleaning:\", type_issues)\n",
    "\n",
    "# 8. Check nulls & duplicates\n",
    "nulls, dupes = check_nulls_and_duplicates(df_cleaned)\n",
    "print(\"Null counts:\\n\", nulls)        # show any remaining missing values\n",
    "print(\"Duplicate rows:\", dupes)       # show count of exact duplicate records\n",
    "\n",
    "# 9. Feature engineering\n",
    "df_model_ready = engineer_features(df_cleaned)\n",
    "# create new numeric columns, scale numbers, encode categories,\n",
    "# and drop any raw ID or timestamp columns inside that function\n",
    "\n",
    "# 10. Define X, y\n",
    "target = 'Fraud_Label' if 'Fraud_Label' in df_model_ready.columns else 'is_fraud'\n",
    "X = df_model_ready.drop(target, axis=1)  \n",
    "y = df_model_ready[target]  \n",
    "# features go in X, the label to predict goes in y\n",
    "\n",
    "if 'Timestamp' in X.columns:\n",
    "    X = X.drop('Timestamp', axis=1)  \n",
    "    # drop any leftover raw datetime column before modeling\n",
    "\n",
    "# 11. Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")  \n",
    "# hold out 20% of data for testing performance on unseen records\n",
    "\n",
    "# 12. Define models (increase max_iter)\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'DecisionTree':       DecisionTreeClassifier(),\n",
    "    'RandomForest':       RandomForestClassifier(),\n",
    "    'KNN':                KNeighborsClassifier()\n",
    "}\n",
    "# list of algorithms we'll train and compare\n",
    "\n",
    "# 13. Train & evaluate\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)         # learn patterns from training data\n",
    "    preds = model.predict(X_test)       # predict on the test set\n",
    "    results.append({\n",
    "        'Model':     name,\n",
    "        'Accuracy':  accuracy_score(y_test, preds),\n",
    "        'Precision': precision_score(y_test, preds),\n",
    "        'Recall':    recall_score(y_test, preds),\n",
    "        'F1':        f1_score(y_test, preds)\n",
    "    })\n",
    "# store accuracy, precision, recall, and F1 for each model\n",
    "\n",
    "# 14. Display results\n",
    "print(pd.DataFrame(results))  \n",
    "# print a table showing how well each classifier performed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1aa3f4",
   "metadata": {},
   "source": [
    "# Results Summary\n",
    "\n",
    "## Nulls and Duplicates\n",
    "\n",
    "All columns report zero missing values and there are no duplicate rows.\n",
    "\n",
    "- The cleaning step filled all nulls and removed duplicates successfully.\n",
    "\n",
    "---\n",
    "\n",
    "## Model Performance\n",
    "\n",
    "| Model              | Accuracy | Precision | Recall  | F1      |\n",
    "|--------------------|---------:|----------:|--------:|--------:|\n",
    "| LogisticRegression |   0.8104 |   0.7335  | 0.6486  | 0.6885 |\n",
    "| DecisionTree       |   1.0000 |   1.0000  | 1.0000  | 1.0000 |\n",
    "| RandomForest       |   1.0000 |   1.0000  | 1.0000  | 1.0000 |\n",
    "| KNN                |   0.7919 |   0.7661  | 0.5121  | 0.6138 |\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "- LogisticRegression  \n",
    "  - Accurately labels about 81% of transactions.  \n",
    "  - Precision 0.73 means 73% of flagged frauds are real.  \n",
    "  - Recall 0.65 means it catches 65% of actual frauds.\n",
    "\n",
    "- DecisionTree and RandomForest  \n",
    "  - Perfect scores (100%) indicate overfitting on the training data.  \n",
    "  - They may fail to generalize to new, unseen data.\n",
    "\n",
    "- KNN  \n",
    "  - Accuracy near 79% and high precision (0.77).  \n",
    "  - Recall 0.51 means it misses almost half of real frauds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
