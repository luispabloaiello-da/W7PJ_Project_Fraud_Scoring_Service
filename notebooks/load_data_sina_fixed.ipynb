{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#for preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df=pd.read_csv (r'../data/raw/synthetic_fraud_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick overview\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and non-null counts\n",
    "print(\"\\nData types and missing values:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for numeric and categorical columns\n",
    "print(\"\\nNumeric summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nCategorical summary:\")\n",
    "display(df.describe(include='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many fraud vs non-fraud\n",
    "print(\"\\nFraud label distribution:\")\n",
    "print(df['Fraud_Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot if you want\n",
    "df['Fraud_Label'].value_counts().plot(kind='bar', title='Fraud vs Non-Fraud')\n",
    "plt.xlabel('Fraud_Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we see how imbalanced it is\n",
    "\n",
    "df['Fraud_Label'].value_counts()\n",
    "df['Fraud_Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick correlation heatmap for numeric columns\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(numeric_only=True), cmap='coolwarm', annot=False)\n",
    "plt.title(\"Numeric Feature Correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Features and Target\n",
    "X = df.drop(columns=['Fraud_Label', 'Transaction_ID', 'User_ID', 'Timestamp'])\n",
    "y = df['Fraud_Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we seperate Numerical Columns\n",
    "\n",
    "numeric_cols = ['Risk_Score', 'Failed_Transaction_Count_7d']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# New preprocessor: only scale these two numeric features\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we build the Pipeline \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=200,\n",
    "        max_depth=None\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is the old codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Failed_to_Total_Ratio'] = df['Failed_Transaction_Count_7d'] / (df['Daily_Transaction_Count'] + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Correlation of each column with the target\n",
    "df.corr(numeric_only=True)['Fraud_Label'].sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a supervised machine learning, Random Forest with scaling \n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "# --- Drop leakage features ---\n",
    "leak_features = ['Failed_Transaction_Count_7d', 'Risk_Score', 'Failed_to_Total_Ratio']\n",
    "X = df.drop(columns=leak_features + ['Fraud_Label'], errors='ignore')\n",
    "y = df['Fraud_Label']\n",
    "\n",
    "# --- Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- Detect column types ---\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# --- Build preprocessor ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Build pipeline ---\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# --- Train and evaluate ---\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "probs = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=['Fraud_Label'])  # target must not be missing\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values in columns\n",
    "df['Account_Balance'] = df['Account_Balance'].fillna(df['Account_Balance'].median())\n",
    "df['Device_Type'] = df['Device_Type'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour'] = df['Timestamp'].dt.hour\n",
    "df['DayOfWeek'] = df['Timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Encode categoricals\n",
    "df = pd.get_dummies(df, columns=['Transaction_Type', 'Device_Type', 'Merchant_Category', 'Card_Type', 'Authentication_Method'], drop_first=True)\n",
    "\n",
    "# Scale numeric columns\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = ['Transaction_Amount', 'Account_Balance', 'Card_Age', 'Transaction_Distance', 'Risk_Score']\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Fraud_Label', axis=1)\n",
    "y = df['Fraud_Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns:\", categorical_cols.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate target\n",
    "y = df['Fraud_Label']\n",
    "X = df.drop(['Fraud_Label', 'Transaction_ID', 'User_ID', 'Timestamp'], axis=1)\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numeric_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('numeric', 'passthrough', numeric_cols)\n",
    "])\n",
    "\n",
    "# Pipeline (preprocessing + model)\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Transaction_ID', 'User_ID', 'Timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns:\", categorical_cols.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplified RandomForest (no scaling)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "#Separate target \n",
    "y = df['Fraud_Label'] \n",
    "X = df.drop(['Fraud_Label', 'Transaction_ID', 'User_ID', 'Timestamp'], axis=1) \n",
    "# Identify categorical and numeric columns \n",
    "categorical_cols = X.select_dtypes(include=['object']).columns \n",
    "numeric_cols = X.select_dtypes(exclude=['object']).columns \n",
    "#Preprocessor \n",
    "preprocessor = ColumnTransformer([ ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_cols), ('numeric', 'passthrough', numeric_cols) ]) \n",
    "#Pipeline (preprocessing + model) \n",
    "model = Pipeline(steps=[ ('preprocessor', preprocessor), ('classifier', RandomForestClassifier()) ]) \n",
    "#Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) \n",
    "#Train \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predicted probabilities (for ROC-AUC)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Model Benchmark (LR, RF, GB)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# --- Split data ---\n",
    "X = df.drop('Fraud_Label', axis=1)\n",
    "y = df['Fraud_Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- Detect column types ---\n",
    "num_cols = X.select_dtypes(include=['int64','float64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns\n",
    "\n",
    "# --- Shared preprocessor ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Define models inside pipelines ---\n",
    "pipelines = {\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('model', LogisticRegression(max_iter=1000))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('model', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    \"GradientBoosting\": Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('model', GradientBoostingClassifier(random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# --- Train and evaluate each ---\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    probs = pipe.predict_proba(X_test)[:, 1]\n",
    "    print(f\"\\n{name}\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_test, probs))\n",
    "    print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one trained pipeline, e.g. the random forest\n",
    "rf_pipeline = pipelines[\"RandomForest\"]\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "ohe = rf_pipeline.named_steps['preprocess'].named_transformers_['cat']\n",
    "encoded_cat_cols = list(ohe.get_feature_names_out(cat_cols))\n",
    "all_features = list(num_cols) + encoded_cat_cols\n",
    "\n",
    "# Get importances\n",
    "importances = rf_pipeline.named_steps['model'].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=all_features).sort_values(ascending=False)\n",
    "\n",
    "print(feat_imp.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feat_imp.head(15).plot(kind='barh', figsize=(8,6))\n",
    "plt.title(\"Top 15 Feature Importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimize Model Hyperparameters\n",
    "\n",
    "# Use GridSearchCV or RandomizedSearchCV to tune the best model:\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [5, 10, 15, None],\n",
    "    'model__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    rf_pipeline, param_grid,\n",
    "    n_iter=10, scoring='roc_auc',\n",
    "    cv=3, random_state=42, n_jobs=-1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best ROC-AUC:\", search.best_score_)\n",
    "print(\"Best Params:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fraud_pipeline import FraudPipeline\n",
    "\n",
    "# pipeline = FraudPipeline(model='random_forest')\n",
    "# pipeline.fit(\"paypal_data.csv\")\n",
    "# # pipeline.predict(\"new_stripe_data.csv\", output=\"fraud_scores.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "origins": "rebuilt"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}