{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "779a647b",
   "metadata": {},
   "source": [
    "**Keep only useful numeric features based on:**\n",
    "-   (A) Two-sample t-tests (group 0 vs. group 1, H0: means are equal)\n",
    "-   (B) VIF analysis to reduce multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec5bf04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# Point to the project root (adjust parents[1] to parents[2] if notebook is deeper)\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# <-- Loads YAML configuration to dynamically reference CSV output files. <-- #\n",
    "\n",
    "config = None  # <-- Initialize config\n",
    "try:\n",
    "    with open(\"../config.yaml\", \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "except:\n",
    "    print(\"Yaml configuration file not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "319cfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Load the dataset\n",
    "df = pd.read_csv(config['input_data']['file1']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ecb65928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (50000, 21)\n",
      "Columns: ['Transaction_ID', 'User_ID', 'Transaction_Amount', 'Transaction_Type', 'Timestamp', 'Account_Balance', 'Device_Type', 'Location', 'Merchant_Category', 'IP_Address_Flag', 'Previous_Fraudulent_Activity', 'Daily_Transaction_Count', 'Avg_Transaction_Amount_7d', 'Failed_Transaction_Count_7d', 'Card_Type', 'Card_Age', 'Transaction_Distance', 'Authentication_Method', 'Risk_Score', 'Is_Weekend', 'Fraud_Label']\n",
      "Fraud_Label\n",
      "0              0.67866\n",
      "1              0.32134\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target_col = \"Fraud_Label\"\n",
    "assert target_col in df.columns, \"Target column Fraud_Label not found.\"\n",
    "\n",
    "# Show quick info\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(df[[target_col]].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0283d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric candidates: ['Transaction_Amount', 'Account_Balance', 'IP_Address_Flag', 'Previous_Fraudulent_Activity', 'Daily_Transaction_Count', 'Avg_Transaction_Amount_7d', 'Failed_Transaction_Count_7d', 'Card_Age', 'Transaction_Distance', 'Risk_Score', 'Is_Weekend']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Step 1 — Select numeric columns (X_num)\n",
    "# =========================\n",
    "# We only work with numeric columns.\n",
    "# We do not include the target column in the numeric feature list.\n",
    "numeric_cols_all = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols_all = [c for c in numeric_cols_all if c != target_col]\n",
    "\n",
    "print(\"\\nNumeric candidates:\", numeric_cols_all)\n",
    "\n",
    "# Simple imputation for numeric columns (median) so tests won't fail due to NaNs\n",
    "for col in numeric_cols_all:\n",
    "    if df[col].isna().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Split data by the target groups (0 and 1)\n",
    "group0 = df[df[target_col] == 0]\n",
    "group1 = df[df[target_col] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b96d0d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T-test results (first 20):\n",
      "                         feature    test_type   mean_group0   mean_group1  \\\n",
      "6    Failed_Transaction_Count_7d  welch_ttest      1.507353      3.051472   \n",
      "9                     Risk_Score  welch_ttest      0.425158      0.662904   \n",
      "4        Daily_Transaction_Count  welch_ttest      7.504877      7.443767   \n",
      "1                Account_Balance  welch_ttest  50356.472852  50162.264626   \n",
      "7                       Card_Age  welch_ttest    120.148056    119.687123   \n",
      "2                IP_Address_Flag   prop_ztest      0.049745      0.051161   \n",
      "0             Transaction_Amount  welch_ttest     99.281907     99.683678   \n",
      "3   Previous_Fraudulent_Activity   prop_ztest      0.098547      0.098089   \n",
      "5      Avg_Transaction_Amount_7d  welch_ttest    255.203530    255.416370   \n",
      "8           Transaction_Distance  welch_ttest   2499.278762   2498.922109   \n",
      "10                    Is_Weekend   prop_ztest      0.299620      0.299683   \n",
      "\n",
      "     p_value decision  \n",
      "6   0.000000     KEEP  \n",
      "9   0.000000     KEEP  \n",
      "4   0.114117     DROP  \n",
      "1   0.481191     DROP  \n",
      "7   0.485136     DROP  \n",
      "2   0.498404     DROP  \n",
      "0   0.671543     DROP  \n",
      "3   0.872467     DROP  \n",
      "5   0.874869     DROP  \n",
      "8   0.979451     DROP  \n",
      "10  0.988590     DROP  \n",
      "\n",
      "Kept after t-test: ['Failed_Transaction_Count_7d', 'Risk_Score']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Step 2 — Two-sample t-tests (Welch)\n",
    "# H0: mean(group0) = mean(group1)\n",
    "# If we REJECT H0 (p < alpha), we KEEP the column (means are different)\n",
    "# Otherwise, we DROP the column\n",
    "# =========================\n",
    "alpha = 0.05  # significance level\n",
    "keep_after_ttest = []\n",
    "ttest_results = []  # will store: [feature, test_type, mean0, mean1, p_value, decision]\n",
    "\n",
    "for col in numeric_cols_all:\n",
    "    # Take the column values per group and drop NaNs just in case\n",
    "    x0 = pd.to_numeric(group0[col], errors=\"coerce\").dropna()\n",
    "    x1 = pd.to_numeric(group1[col], errors=\"coerce\").dropna()\n",
    "    \n",
    "    # --- Just to SEE the means (not required for the test) ---\n",
    "    mean0 = x0.mean() if len(x0) > 0 else np.nan\n",
    "    mean1 = x1.mean() if len(x1) > 0 else np.nan\n",
    "    \n",
    "    # --- If the column is binary (only 0/1 values), use proportions test ---\n",
    "    unique_vals = pd.Series(pd.concat([x0, x1], axis=0).unique())\n",
    "    is_binary = unique_vals.dropna().isin([0,1]).all()\n",
    "\n",
    "    if is_binary:\n",
    "        # ----- Two-proportions z-test for binary columns -----\n",
    "        # successes = count of 1s; nobs = total observations in each group\n",
    "        count = np.array([(x0 == 1).sum(), (x1 == 1).sum()])\n",
    "        nobs  = np.array([len(x0), len(x1)])\n",
    "\n",
    "        # basic safety checks\n",
    "        if (nobs < 2).any():  # too few observations in a group → skip\n",
    "            p_value = np.nan\n",
    "            decision = \"DROP (not enough data)\"\n",
    "            reject = False\n",
    "        else:\n",
    "            # z-test for difference in proportions\n",
    "            stat, p_value = proportions_ztest(count, nobs)  # Two-proportion Z-test (two-sided)\n",
    "            reject = (p_value < alpha)\n",
    "            decision = \"KEEP\" if reject else \"DROP\"\n",
    "\n",
    "        ttest_results.append([col, \"prop_ztest\", mean0, mean1, p_value, decision])\n",
    "        \n",
    "        if reject:\n",
    "            keep_after_ttest.append(col)\n",
    "    else:\n",
    "        # ----- Welch's two-sample t-test for continuous columns -----\n",
    "        # If any group has too few values or zero variance, t-test can be unstable\n",
    "        if len(x0) < 5 or len(x1) < 5:\n",
    "            p_value = np.nan\n",
    "            decision = \"DROP (not enough variation/data)\"\n",
    "            reject = False\n",
    "        elif x0.std(ddof=1) == 0 or x1.std(ddof=1) == 0:\n",
    "            p_value = np.nan\n",
    "            decision = \"DROP (not enough variation/data)\"\n",
    "            reject = False\n",
    "        else:\n",
    "            # Welch's t-test (doesn't assume equal variances)\n",
    "            t_stat, p_value = stats.ttest_ind(x0, x1, equal_var=False)  # Welch's t-test (one-sided)\n",
    "            reject = (p_value < alpha)\n",
    "            decision = \"KEEP\" if reject else \"DROP\"\n",
    "\n",
    "        ttest_results.append([col, \"welch_ttest\", mean0, mean1, p_value, decision])\n",
    "        \n",
    "        if reject:\n",
    "            keep_after_ttest.append(col)\n",
    "\n",
    "# Show t-test summary\n",
    "ttest_df = pd.DataFrame(ttest_results, columns=[\"feature\", \"test_type\", \"mean_group0\", \"mean_group1\", \"p_value\", \"decision\"])\n",
    "print(\"\\nT-test results (first 20):\")\n",
    "print(ttest_df.sort_values(\"p_value\", na_position=\"last\").head(20))\n",
    "print(\"\\nKept after t-test:\", keep_after_ttest)\n",
    "\n",
    "# If nothing passed (rare), fall back to using all numeric cols to avoid empty set\n",
    "if len(keep_after_ttest) == 0:\n",
    "    print(\"\\n[Note] No columns passed the t-test threshold; using all numeric columns as fallback.\")\n",
    "    keep_after_ttest = numeric_cols_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e8989cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VIF table (including constant):\n",
      "                       feature       VIF\n",
      "0                        const  6.040628\n",
      "1  Failed_Transaction_Count_7d  1.000001\n",
      "2                   Risk_Score  1.000001\n",
      "\n",
      "High VIF features (> 5.0): []\n",
      "\n",
      "Final kept numeric features after t-test and VIF:\n",
      "['Failed_Transaction_Count_7d', 'Risk_Score']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Step 3 — VIF analysis (on remaining columns)\n",
    "# We do NOT include the target in the VIF input.\n",
    "# Steps:\n",
    "#   - Build X with the kept columns\n",
    "#   - Add a constant (intercept) for VIF calculation\n",
    "#   - Compute VIF for each feature\n",
    "#   - Drop features with high VIF (e.g., > 5 or > 10). We'll use 5 here.\n",
    "# =========================\n",
    "vif_threshold = 5.0  # common thresholds are 5 or 10; we choose 5 to be stricter\n",
    "\n",
    "# numeric_cols_all = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# numeric_cols_all = [c for c in numeric_cols_all if c not in keep_after_ttest]\n",
    "\n",
    "# Build design matrix with the kept columns\n",
    "X_vif = df[keep_after_ttest].copy()\n",
    "\n",
    "# If any new NaNs appeared, fill them to avoid VIF errors\n",
    "for col in X_vif.columns:\n",
    "    if X_vif[col].isna().any():\n",
    "        X_vif[col] = X_vif[col].fillna(X_vif[col].median())\n",
    "\n",
    "# Add constant for VIF calculation\n",
    "X_vif_const = sm.add_constant(X_vif, has_constant=\"add\")\n",
    "\n",
    "# Compute VIF for each feature (excluding the constant itself when reporting)\n",
    "vif_data = []\n",
    "for i, col in enumerate(X_vif_const.columns):\n",
    "    vif_val = variance_inflation_factor(X_vif_const.values, i)\n",
    "    vif_data.append([col, vif_val])\n",
    "\n",
    "vif_df = pd.DataFrame(vif_data, columns=[\"feature\", \"VIF\"])\n",
    "print(\"\\nVIF table (including constant):\")\n",
    "print(vif_df)\n",
    "\n",
    "# Filter to features only (exclude constant)\n",
    "vif_features_df = vif_df[vif_df[\"feature\"] != \"const\"].copy()\n",
    "\n",
    "# Identify high VIF features\n",
    "high_vif = vif_features_df[vif_features_df[\"VIF\"] > vif_threshold][\"feature\"].tolist()\n",
    "print(\"\\nHigh VIF features (> {}):\".format(vif_threshold), high_vif)\n",
    "\n",
    "# Drop high VIF features in one pass (simple approach)\n",
    "final_kept = [c for c in keep_after_ttest if c not in high_vif]\n",
    "\n",
    "# If everything gets dropped (rare), keep the lowest-VIF feature as a fallback\n",
    "if len(final_kept) == 0:\n",
    "    lowest_vif_row = vif_features_df.sort_values(\"VIF\").head(1)\n",
    "    final_kept = lowest_vif_row[\"feature\"].tolist()\n",
    "\n",
    "print(\"\\nFinal kept numeric features after t-test and VIF:\")\n",
    "print(final_kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a38cb477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected data shape: (50000, 3)\n",
      "Saved kept numeric features to: ../data/clean/selected_fraud_dataset.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Failed_Transaction_Count_7d</th>\n",
       "      <th>Risk_Score</th>\n",
       "      <th>Fraud_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Failed_Transaction_Count_7d  Risk_Score  Fraud_Label\n",
       "0                            3      0.8494            0\n",
       "1                            4      0.0959            1\n",
       "2                            4      0.8400            1\n",
       "3                            4      0.7935            1\n",
       "4                            4      0.3819            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved kept numeric features to: ../data/clean/selected_numeric_features.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Failed_Transaction_Count_7d\n",
       "1                     Risk_Score\n",
       "Name: kept_numeric_features, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# Step 4 — Summary / Next step\n",
    "# =========================\n",
    "# 'final_kept' is our cleaned numeric feature list to use it in KNN/scaling.\n",
    "selected_df = df[final_kept + [target_col]].copy().reset_index(drop=True)\n",
    "print(\"\\nSelected data shape:\", selected_df.shape)\n",
    "\n",
    "# Save the final df with kept columns + target_col to a CSV for reuse in other notebooks\n",
    "selected_df.to_csv(config['output_data']['file1'], index=False, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved kept numeric features to:\", config['output_data']['file1'])\n",
    "display(selected_df.head())\n",
    "\n",
    "# turn list -> Series with a name so 02-notebook can read the column by name\n",
    "final_kept = pd.Series(final_kept, name=\"kept_numeric_features\")\n",
    "\n",
    "# Save the kept column names to a CSV for reuse in other notebooks\n",
    "final_kept.to_csv(config['output_data']['file2'], index=False, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved kept numeric features to:\", config['output_data']['file2'])\n",
    "display(final_kept.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "W7PJ_Project_Fraud_Detection_Transactions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
